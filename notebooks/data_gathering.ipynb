{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb35c53b",
   "metadata": {},
   "source": [
    "# Data gathering from Boxoffice Mojo website and OMDB api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping data for movies boxoffice from www.boxofficemojo.com\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "final_list = []\n",
    "\n",
    "#scrape all tables for boxoffice data using Beautifulsoup\n",
    "for i in range(1, 48000,200):\n",
    "    try:\n",
    "        page = 'https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW&offset=' + str(i)\n",
    "        resp = requests.get(page)\n",
    "        soup = BeautifulSoup(resp.text, 'lxml')\n",
    "        table_data = [x.text for x in soup.select('tr td')[0:1600]]  # trial and error to get the exact positions\n",
    "        temp_list = [table_data[i:i+8] for i in range(0, len(table_data[:-7]), 8)] # put every 5 values in a row\n",
    "        for temp in temp_list:\n",
    "            final_list.append(temp)\n",
    "    except Exception as e:\n",
    "        break\n",
    "\n",
    "regex = '|'.join(['\\$', ',', '\\^'])\n",
    "\n",
    "# making a dataframe using the data\n",
    "columns = ['rank', 'title', 'Worldwide_lifetime_Gross','Domestic_Lifetime_Gross','Domestic_%','Foreign_Lifetime_Gross', 'Foreign_%','year']\n",
    "boxoffice_df = pd.DataFrame({\n",
    "    'rank': [(x[0]) for x in final_list],  # convert ranks to integers\n",
    "    'title': [x[1] for x in final_list],  # get titles as is\n",
    "    'Worldwide_Lifetime_Gross': [int(re.sub(regex, '', x[2])) for x in final_list],  # remove special characters and convert to integer\n",
    "    'Domestic_Lifetime_Gross':[(re.sub(regex, '', x[3])) for x in final_list],\n",
    "    'Domestic_%':[(re.sub(regex, '', x[4])) for x in final_list],\n",
    "    'Foreign_Lifetime_Gross':[int(re.sub(regex, '', x[5])) for x in final_list],\n",
    "    'Foreign_%':[(re.sub(regex, '', x[6])) for x in final_list],\n",
    "    'year': [int(re.sub(regex, '',str(x[7]))) for x in final_list],  # remove special characters and convert to integer\n",
    "})\n",
    "\n",
    "# adding the first row manually\n",
    "line1=pd.DataFrame({'rank':'1','title':'Avatar','Worldwide_Lifetime_Gross':'2847246203','Domestic_Lifetime_Gross':'760507625','Domestic_%':'26.7%','Foreign_Lifetime_Gross':'2086738578','Foreign_%' :'73.3%','year':'2009'},index=[0])\n",
    "boxoffice = pd.concat([line1,boxoffice_df],ignore_index=True)\n",
    "\n",
    "#changing the data type and delete unwanted character\n",
    "boxoffice['rank'].replace(',','', regex=True, inplace=True)\n",
    "boxoffice = boxoffice.astype({'rank': int, 'title': str,'Worldwide_Lifetime_Gross':int,'year':int})\n",
    "\n",
    "#delete unwanted columns\n",
    "boxoffice.drop(columns = ['rank','Domestic_%','Foreign_%'], inplace=True,)\n",
    "\n",
    "#saving to csv\n",
    "boxoffice.to_csv('/Users/Amin/Documents/GitHub/Movie_boxoffice_reviews/data/interim/mojo_clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af929ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data for Metacritic from OMDB api\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "#getting the imdb_id row from imdb file to use it for requesting api\n",
    "imdb = pd.read_csv('/Users/Amin/Documents/GitHub/Movie_boxoffice_reviews/data/interim/IMDB_clean.csv')\n",
    "imdb = imdb[imdb['year'] >= 2010]\n",
    "imdb = imdb[['imdb_title_id','year']]\n",
    "imdb = imdb.sort_values('year',ignore_index=True,ascending=False)\n",
    "id_list = imdb['imdb_title_id'].tolist()\n",
    "\n",
    "#getting single request to get the columns name\n",
    "url = ('http://www.omdbapi.com/?i=tt2850272&apikey=e8935e9')\n",
    "r = requests.get(url)\n",
    "json_data = r.json()\n",
    "col = json_data.keys()\n",
    "\n",
    "#creating an empty dataframe using the columns name\n",
    "omdb = pd.DataFrame(columns=col)\n",
    "\n",
    "#use the id list to request all the data from the api and append it to the dataframe\n",
    "for id in id_list:\n",
    "    url = ('http://www.omdbapi.com/?i='+id + '&apikey=e8935e9')\n",
    "    r = requests.get(url)\n",
    "    json_data = r.json()\n",
    "    omdb = omdb.append(json_data, ignore_index=True)\n",
    "\n",
    "#selecting the columns that needed for merge and Metascore value\n",
    "omdb = omdb[['imdbID','Title','Director','Year','Released','Runtime','Metascore']]\n",
    "omdb.dropna(subset=['Metascore'],inplace = True)\n",
    "\n",
    "\n",
    "#save the dataframe to csv file \n",
    "omdb.to_csv('/Users/Amin/Documents/GitHub/Movie_boxoffice_reviews/data/interim/Omdb_clean.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41603908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
