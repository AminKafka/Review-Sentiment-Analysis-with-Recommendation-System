{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2920d8",
   "metadata": {},
   "source": [
    "# 3- Review Sentiment Prediction:\n",
    "#### Amin Khoeini\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "In this step, diffrent NLP model will train to see which one has the best performance for the sentiment prediction of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d667acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import pow, sqrt\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,SnowballStemmer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5c0115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "review_db = pd.read_csv('/Users/Amin/Documents/GitHub/Review-Sentiment-Analysis-with-Recommendation-System/data/review_db.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4367f927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_detail</th>\n",
       "      <th>lable</th>\n",
       "      <th>imdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OriginalMovieBuff21</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2005-07-24</td>\n",
       "      <td>after seeing tarantino's kill bill vol: 1 i go...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bogmeister</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005-08-15</td>\n",
       "      <td>the 2nd half of tarantino's tale of bloody rev...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>departed07</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2005-08-26</td>\n",
       "      <td>the bride is back and ready to kick ass in thi...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angeneer</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2005-09-08</td>\n",
       "      <td>i'm very happy to admit that tarantino proved ...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LoneWolfAndCub</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2005-09-07</td>\n",
       "      <td>kill bill volume 2 (directed by quentin tarant...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewer               movie  rating review_date  \\\n",
       "0  OriginalMovieBuff21  Kill Bill: Vol. 2      8.0  2005-07-24   \n",
       "1           Bogmeister  Kill Bill: Vol. 2      9.0  2005-08-15   \n",
       "2           departed07  Kill Bill: Vol. 2     10.0  2005-08-26   \n",
       "3             Angeneer  Kill Bill: Vol. 2     10.0  2005-09-08   \n",
       "4       LoneWolfAndCub  Kill Bill: Vol. 2     10.0  2005-09-07   \n",
       "\n",
       "                                       review_detail    lable    imdb_id  \n",
       "0  after seeing tarantino's kill bill vol: 1 i go...  LOVE IT  tt0378194  \n",
       "1  the 2nd half of tarantino's tale of bloody rev...  LOVE IT  tt0378194  \n",
       "2  the bride is back and ready to kick ass in thi...  LOVE IT  tt0378194  \n",
       "3  i'm very happy to admit that tarantino proved ...  LOVE IT  tt0378194  \n",
       "4  kill bill volume 2 (directed by quentin tarant...  LOVE IT  tt0378194  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b60693e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewer          object\n",
       "movie             object\n",
       "rating           float64\n",
       "review_date       object\n",
       "review_detail     object\n",
       "lable             object\n",
       "imdb_id           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_db.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27f36559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a unique ID for each user_name.\n",
    "review_db['User_ID'] = review_db.reviewer.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea89c293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2401,  381, 5284, ..., 9152, 8056, 8807], dtype=int16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_db.User_ID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafbd863",
   "metadata": {},
   "source": [
    "### Processing the Review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2aaae11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the punctuation from the review\n",
    "def punc_clean(text):\n",
    "    import string as st\n",
    "    a=[w for w in text if w not in st.punctuation]\n",
    "    return ''.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cce63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the punc_clean function to the review\n",
    "review_db['review_clean'] = review_db['review_detail'].apply(punc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae5b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stop words from the review\n",
    "def remove_stopword(text):\n",
    "    stopword=nltk.corpus.stopwords.words('english')\n",
    "    stopword.remove('not')\n",
    "    return ' '.join(w for w in nltk.word_tokenize(text) if w not in stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcde2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the remove_stopword to the review\n",
    "review_db['review_clean'] = review_db['review_clean'].apply(remove_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0031b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any only numeric string from the review\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "words = set(nltk.corpus.words.words())\n",
    "def clean(text):\n",
    "    return ' '.join([w for w in w_tokenizer.tokenize(text) if w.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc686782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply remove numeric function to review \n",
    "review_db['review_clean'] = review_db['review_processed'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3058f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize the review by using sklearn WordNetLemmatizer\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8420ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Lemmatizer to review\n",
    "review_db['review_clean'] = review_db['review_clean'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b367aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemme the review using Sklearn SnowballStemmer and only chose english words\n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "def stemmer_text(text):\n",
    "    return ' '.join([stemmer.stem(w) for w in w_tokenizer.tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c083333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the stemmer to review\n",
    "review_db['review_clean'] = review_db['review_clean'].apply(stemmer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cd2e92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_detail</th>\n",
       "      <th>lable</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OriginalMovieBuff21</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2005-07-24</td>\n",
       "      <td>after seeing tarantino's kill bill vol: 1 i go...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "      <td>2401</td>\n",
       "      <td>seeing tarantino kill bill vol 1 got watch vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bogmeister</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005-08-15</td>\n",
       "      <td>the 2nd half of tarantino's tale of bloody rev...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "      <td>381</td>\n",
       "      <td>2nd half tarantino tale bloody revenge doesnt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>departed07</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2005-08-26</td>\n",
       "      <td>the bride is back and ready to kick ass in thi...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "      <td>5284</td>\n",
       "      <td>bride back ready kick as conclusion two part s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angeneer</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2005-09-08</td>\n",
       "      <td>i'm very happy to admit that tarantino proved ...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "      <td>167</td>\n",
       "      <td>im happy admit tarantino proved wrong read rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LoneWolfAndCub</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2005-09-07</td>\n",
       "      <td>kill bill volume 2 (directed by quentin tarant...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "      <td>1906</td>\n",
       "      <td>kill bill volume 2 directed quentin tarantino ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewer               movie  rating review_date  \\\n",
       "0  OriginalMovieBuff21  Kill Bill: Vol. 2      8.0  2005-07-24   \n",
       "1           Bogmeister  Kill Bill: Vol. 2      9.0  2005-08-15   \n",
       "2           departed07  Kill Bill: Vol. 2     10.0  2005-08-26   \n",
       "3             Angeneer  Kill Bill: Vol. 2     10.0  2005-09-08   \n",
       "4       LoneWolfAndCub  Kill Bill: Vol. 2     10.0  2005-09-07   \n",
       "\n",
       "                                       review_detail    lable    imdb_id  \\\n",
       "0  after seeing tarantino's kill bill vol: 1 i go...  LOVE IT  tt0378194   \n",
       "1  the 2nd half of tarantino's tale of bloody rev...  LOVE IT  tt0378194   \n",
       "2  the bride is back and ready to kick ass in thi...  LOVE IT  tt0378194   \n",
       "3  i'm very happy to admit that tarantino proved ...  LOVE IT  tt0378194   \n",
       "4  kill bill volume 2 (directed by quentin tarant...  LOVE IT  tt0378194   \n",
       "\n",
       "   User_ID                                       review_clean  \n",
       "0     2401  seeing tarantino kill bill vol 1 got watch vol...  \n",
       "1      381  2nd half tarantino tale bloody revenge doesnt ...  \n",
       "2     5284  bride back ready kick as conclusion two part s...  \n",
       "3      167  im happy admit tarantino proved wrong read rev...  \n",
       "4     1906  kill bill volume 2 directed quentin tarantino ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f72930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_db.to_csv('/Users/Amin/Documents/GitHub/Review-Sentiment-Analysis-with-Recommendation-System/data/process_db.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec2b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_db = pd.read_csv('/Users/Amin/Documents/GitHub/Review-Sentiment-Analysis-with-Recommendation-System/data/process_db.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e66ba53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_detail</th>\n",
       "      <th>lable</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OriginalMovieBuff21</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2005-07-24</td>\n",
       "      <td>after seeing tarantino's kill bill vol: 1 i go...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "      <td>2401</td>\n",
       "      <td>seeing tarantino kill bill vol 1 got watch vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bogmeister</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005-08-15</td>\n",
       "      <td>the 2nd half of tarantino's tale of bloody rev...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "      <td>381</td>\n",
       "      <td>2nd half tarantino tale bloody revenge doesnt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>departed07</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2005-08-26</td>\n",
       "      <td>the bride is back and ready to kick ass in thi...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "      <td>5284</td>\n",
       "      <td>bride back ready kick as conclusion two part s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angeneer</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2005-09-08</td>\n",
       "      <td>i'm very happy to admit that tarantino proved ...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "      <td>167</td>\n",
       "      <td>im happy admit tarantino proved wrong read rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LoneWolfAndCub</td>\n",
       "      <td>Kill Bill: Vol. 2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2005-09-07</td>\n",
       "      <td>kill bill volume 2 (directed by quentin tarant...</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>tt0378194</td>\n",
       "      <td>1906</td>\n",
       "      <td>kill bill volume 2 directed quentin tarantino ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewer               movie  rating review_date  \\\n",
       "0  OriginalMovieBuff21  Kill Bill: Vol. 2      8.0  2005-07-24   \n",
       "1           Bogmeister  Kill Bill: Vol. 2      9.0  2005-08-15   \n",
       "2           departed07  Kill Bill: Vol. 2     10.0  2005-08-26   \n",
       "3             Angeneer  Kill Bill: Vol. 2     10.0  2005-09-08   \n",
       "4       LoneWolfAndCub  Kill Bill: Vol. 2     10.0  2005-09-07   \n",
       "\n",
       "                                       review_detail    lable    imdb_id  \\\n",
       "0  after seeing tarantino's kill bill vol: 1 i go...  LOVE IT  tt0378194   \n",
       "1  the 2nd half of tarantino's tale of bloody rev...  LOVE IT  tt0378194   \n",
       "2  the bride is back and ready to kick ass in thi...  LOVE IT  tt0378194   \n",
       "3  i'm very happy to admit that tarantino proved ...  LOVE IT  tt0378194   \n",
       "4  kill bill volume 2 (directed by quentin tarant...  LOVE IT  tt0378194   \n",
       "\n",
       "   User_ID                                       review_clean  \n",
       "0     2401  seeing tarantino kill bill vol 1 got watch vol...  \n",
       "1      381  2nd half tarantino tale bloody revenge doesnt ...  \n",
       "2     5284  bride back ready kick as conclusion two part s...  \n",
       "3      167  im happy admit tarantino proved wrong read rev...  \n",
       "4     1906  kill bill volume 2 directed quentin tarantino ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574ed30",
   "metadata": {},
   "source": [
    "### Make a Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e0ff55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the procced review column to X_train/X_test and lable column as y\n",
    "X_train,X_test,y_train,y_test = train_test_split(review_db.review_clean,review_db.lable,test_size=0.2, \n",
    "                                                    random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fa0cb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467379    owen shaw hospital darkops brother deckard sha...\n",
       "33918     first scene see bunch guy tuxedo eating talkin...\n",
       "475802    try telling parent live tumultuous time theyll...\n",
       "206763    always liked chase movie watch like see subtle...\n",
       "202948    perfect amazing fascinatingthose 3 word would ...\n",
       "Name: review_clean, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5366ee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467379    NOT LOVE IT\n",
       "33918         LOVE IT\n",
       "475802        LOVE IT\n",
       "206763    NOT LOVE IT\n",
       "202948        LOVE IT\n",
       "Name: lable, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc2a40",
   "metadata": {},
   "source": [
    "### Vectorize the Processed Review Column with Count and Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f742af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count_vector from the review\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9df3447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aardvark', 'aba', ..., 'zygomat', 'zygon', 'zygot'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06e7ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tfidf_vector from the review\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True,max_df=0.7,sublinear_tf=True)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2dd7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Tfidf vectorizer for later use in model\n",
    "pickle.dump(tfidf_vectorizer,open('tfidf.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27b3d202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000', ..., '警察故事', '酸奶', '魔女の宅急便'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f2be5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383652, 935670)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98523dd2",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bfb902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7537768602796284\n",
      "[[33549 11018]\n",
      " [12598 38748]]\n"
     ]
    }
   ],
   "source": [
    "# create a instant of Naive Bayes Classifier and train it with count_train\n",
    "nb_classifier_count = MultinomialNB(alpha=0.3)\n",
    "nb_classifier_count.fit(count_train,y_train)\n",
    "pred_count = nb_classifier_count.predict(count_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test,pred_count)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test,pred_count,labels=['LOVE IT','NOT LOVE IT'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce80c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(nb_classifier_count, count_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6708bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([6.48427796, 2.95213389, 3.44983816, 3.72382116, 3.67701912]),\n",
       " 'score_time': array([0.82861185, 0.76128101, 0.64674902, 0.6545248 , 0.60610414]),\n",
       " 'test_score': array([0.75388044, 0.75145639, 0.75249576, 0.75472436, 0.75559755])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4098576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Hyperparammeters Tunning to see if We Can Get Better Result\n",
    "alphas = np.arange(0,1,0.1)\n",
    "nb_param = {'alpha':alphas}\n",
    "nb_grid_cv = GridSearchCV(nb_classifier, param_grid=nb_param, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45bbd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid_cv.fit(count_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77a455d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.30000000000000004}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c515b52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75625901097629\n",
      "[[33149 10835]\n",
      " [12326 38713]]\n"
     ]
    }
   ],
   "source": [
    "pred_cv = nb_grid_cv.best_estimator_.predict(count_test)\n",
    "\n",
    "score = metrics.accuracy_score(y_test,pred_cv)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test,pred_cv,labels=['LOVE IT','NOT LOVE IT'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb9bf83",
   "metadata": {},
   "source": [
    "HyperParameters tunnign didn't change the result and Naive Bayes classifier with count vector return 75% accuracy for review sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e599a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7488557338421278\n",
      "[[30157 14410]\n",
      " [ 9678 41668]]\n"
     ]
    }
   ],
   "source": [
    "# Create instant of Naive Bayes classifier with Tfidf Vector\n",
    "nb_classifier_tfidf = MultinomialNB(alpha = 0.3)\n",
    "nb_classifier_tfidf.fit(tfidf_train,y_train)\n",
    "pred_tfidf = nb_classifier_tfidf.predict(tfidf_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test,pred_tfidf)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test,pred_tfidf,labels=['LOVE IT','NOT LOVE IT'])\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "127633b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([5.93301916, 2.28874493, 2.30643773, 2.18597984, 2.23750401]),\n",
       " 'score_time': array([0.45556188, 0.42716789, 0.32579613, 0.33568096, 0.32654405]),\n",
       " 'test_score': array([0.75184736, 0.74823735, 0.74758243, 0.75038447, 0.75230027])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = cross_validate(nb_classifier_tfidf, tfidf_train, y_train, cv=5)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "399c2e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tfidf_grid_cv = GridSearchCV(nb_classifier2, param_grid=nb_param, cv=5, n_jobs=-1)\n",
    "nb_tfidf_grid_cv.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8552dad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tfidf_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2404220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7525967397366953\n",
      "[[30334 13650]\n",
      " [ 9859 41180]]\n"
     ]
    }
   ],
   "source": [
    "pred_cv = nb_tfidf_grid_cv.best_estimator_.predict(tfidf_test)\n",
    "\n",
    "score = metrics.accuracy_score(y_test,pred_cv)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test,pred_cv,labels=['LOVE IT','NOT LOVE IT'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef0c0e2",
   "metadata": {},
   "source": [
    "Same happens for the tfidf, not much of a diffrent with Hyperparameters tunning and get the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26babf8d",
   "metadata": {},
   "source": [
    "### LogisticRegression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb63f256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7867650891954167\n",
      "[[33934 10633]\n",
      " [ 9819 41527]]\n"
     ]
    }
   ],
   "source": [
    "# Create a instant of LogisticRegression Classifier and train it with count vector\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr_classifier = lr.fit(count_train,y_train)\n",
    "pred_lr = lr_classifier.predict(count_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test,pred_lr)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test,pred_lr,labels=['LOVE IT','NOT LOVE IT'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fc1e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8007360837425583\n",
      "[[34729  9838]\n",
      " [ 9274 42072]]\n"
     ]
    }
   ],
   "source": [
    "# Create a instant of LogisticRegression Classifier and train it with Tfidf Vector\n",
    "lr_tfidf = LogisticRegression(max_iter=10000)\n",
    "lr_classifier_tfidf = lr_tfidf.fit(tfidf_train,y_train)\n",
    "pred_lr_tfidf = lr_classifier_tfidf.predict(tfidf_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test,pred_lr_tfidf)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test,pred_lr_tfidf,labels=['LOVE IT','NOT LOVE IT'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66747775",
   "metadata": {},
   "source": [
    "LogisticRegression Classifier trained with tfidf return slightly better result but it is very slow with our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf252989",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef414cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797274613451774\n",
      "[[34699  9868]\n",
      " [ 9576 41770]]\n"
     ]
    }
   ],
   "source": [
    "# Create a instant of Linear Support Vector Classifier and train it with Tfidf vector\n",
    "lsvc = LinearSVC()\n",
    "\n",
    "svm_classifier = lsvc.fit(tfidf_train,y_train)\n",
    "\n",
    "pred_svm = svm_classifier.predict(tfidf_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test,pred_svm)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test,pred_svm,labels=['LOVE IT','NOT LOVE IT'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3813bc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': ['l1', 'l2'],\n",
       " 'loss': ['hinge', 'squared_hinge'],\n",
       " 'C': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters Tune another instant of Linear Support Vector Classifier to see if we can get better result\n",
    "c = np.arange(1,11)\n",
    "lsvc_param = {'penalty':['l1','l2'],\n",
    "              'loss': ['hinge', 'squared_hinge'],\n",
    "              'C': c}\n",
    "lsvc_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f740b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.79845457        nan 0.79274537        nan 0.79500274\n",
      "        nan 0.7872098         nan 0.79214287        nan 0.78297131\n",
      "        nan 0.78986971        nan 0.77977205        nan 0.78727558\n",
      "        nan 0.77722528        nan 0.78526552        nan 0.77487845\n",
      "        nan 0.78343173        nan 0.77271053        nan 0.78170581\n",
      "        nan 0.77083465        nan 0.78014302        nan 0.76927185\n",
      "        nan 0.77904064        nan 0.76768275]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={'C': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                         'loss': ['hinge', 'squared_hinge'],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_grid_cv = GridSearchCV(lsvc, param_grid=lsvc_param, cv=5, n_jobs=-1)\n",
    "\n",
    "lsvc_grid_cv.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8512421f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'loss': 'hinge', 'penalty': 'l2'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a851f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8015848794502384\n",
      "[[34745  9239]\n",
      " [ 9615 41424]]\n"
     ]
    }
   ],
   "source": [
    "pred_cv = lsvc_grid_cv.best_estimator_.predict(tfidf_test)\n",
    "\n",
    "score = metrics.accuracy_score(y_test,pred_cv)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test,pred_cv,labels=['LOVE IT','NOT LOVE IT'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44109fef",
   "metadata": {},
   "source": [
    "Slightly better acuracy and faster than LogisticRegressor Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a95db57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8034155953833161\n",
      "[[35169  9398]\n",
      " [ 9457 41889]]\n"
     ]
    }
   ],
   "source": [
    "# Using the Hyperparameters to train new instant of the Linear Support Vector Classifier with max_iteration set to 10000\n",
    "lsvc_tfidf = LinearSVC(C=1, loss='hinge', penalty = 'l2',max_iter=10000)\n",
    "lsvc_tfidf.fit(tfidf_train,y_train)\n",
    "pred_cv_tfidf = lsvc_tfidf.predict(tfidf_test)\n",
    "\n",
    "score = metrics.accuracy_score(y_test,pred_cv_tfidf)\n",
    "print(score)\n",
    "cm = metrics.confusion_matrix(y_test,pred_cv_tfidf,labels=['LOVE IT','NOT LOVE IT'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db83b69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     LOVE IT       0.79      0.79      0.79     44567\n",
      " NOT LOVE IT       0.82      0.82      0.82     51346\n",
      "\n",
      "    accuracy                           0.80     95913\n",
      "   macro avg       0.80      0.80      0.80     95913\n",
      "weighted avg       0.80      0.80      0.80     95913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the report for the final Linear Support Vector Classifier model\n",
    "report = metrics.classification_report(y_test,pred_cv_tfidf)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f057da",
   "metadata": {},
   "source": [
    "Let's try some reviews and see how model works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afb368e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT LOVE IT'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = 'if you want to see a entertaining movie avoid this film by all means'\n",
    "review = punc_clean(review)\n",
    "review = lemmatize_text(review)\n",
    "review = remove_stopword(review)\n",
    "review = tfidf_vectorizer.transform([review])\n",
    "lsvc_tfidf.predict(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ebea600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LOVE IT'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"can't be better than this, one of the best movie i ever saw\"\n",
    "review = punc_clean(review)\n",
    "review = lemmatize_text(review)\n",
    "review = remove_stopword(review)\n",
    "review = tfidf_vectorizer.transform([review])\n",
    "lsvc_tfidf.predict(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1caeaa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT LOVE IT'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = 'waste of the time and money'\n",
    "review = punc_clean(review)\n",
    "review = lemmatize_text(review)\n",
    "review = remove_stopword(review)\n",
    "review = tfidf_vectorizer.transform([review])\n",
    "lsvc_tfidf.predict(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5dcd17",
   "metadata": {},
   "source": [
    "Model has a good performance for obvious review. Let's check it with real and longer review from imdb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e53ca7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT LOVE IT'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Real review for a movie that user gave 5/10 so model should lable it as NOT LOVE IT\n",
    "review = \"Unfortunately it is protracted and drawn out. Kudos for 'showing-not-telling', but there are so many stretches of uninteresting dialogue. Everybody plays their part well - the whole is less than the sum of the parts. Not sure why this is - the cast is strong with good actors I have enjoyed before. Perhaps it is the pretension of becoming the new 2001 overriding the need to make a compelling movie.\"\n",
    "review = punc_clean(review)\n",
    "review = lemmatize_text(review)\n",
    "review = remove_stopword(review)\n",
    "review = tfidf_vectorizer.transform([review])\n",
    "lsvc_tfidf.predict(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81a95c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT LOVE IT'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Real long and complicated review with refrence to other movie. The user gave 6/10 so we excpect NOT LOVE IT.\n",
    "review = \"This is a movie with plenty of things going for it. Great performances, incredible visual effects, an interesting story, and tons of really cool concepts, which make for a few genuinely powerful scenes, However, that doesn't make it the flawless masterpiece of cinematic genius everybody is labeling it as. There are tons of people giving this movie 10/10 ratings, leading to a user rating of 8.7, and it is now #29 on the IMDb top 250. WOW! That is a lot of praise! On the top 250, Interstellar is above Casablanca, Raiders of the Lost Ark, Psycho, Apocalypse Now, and CITIZEN KANE! According to the users on IMDb, this movie's better than Citizen Kane, which has been known as possibly the greatest film of all time! Is is better than Citizen Kane? No, not even close. The film is full of flaws, the biggest being the runtime. I may never see this movie again because of how long it felt! It feels like a lot of scenes are unneeded, and were made just so the movie could be longer, because Christopher Nolan wanted to make it seem really epic. I'm sure if Nolan cut a huge chunk of the movie out, it would've been better. A film by Nolan that is better than this one is The Dark Knight, which has a somewhat long runtime, but it feels way shorter than it's runtime, and is extremely entertaining throughout. Interstellar is so long that it starts to really drag on and, at times, I began to just zone out.The film is also a bit too dramatic. The dialogue about how love conquers all seemed very unnecessarily corny, as well as a few other select scenes in the movie. However, some sequences were quite powerful, especially the ending, which, actually, was kind of creepy. The concept of time was very prominent throughout the film, and it lead to some pretty creative and powerful sequences.Overall, the film is recommended, but you should be warned that this movie was LOOOOOOOONG!!!!!!\"\n",
    "review = lemmatize_text(review)\n",
    "review = remove_stopword(review)\n",
    "review = tfidf_vectorizer.transform([review])\n",
    "lsvc_tfidf.predict(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "426b54fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LOVE IT'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another long review with 7/10 score so we excpect LOVE IT.\n",
    "review = \"Interstellar is set in the future where crop blights and dust storms threaten human survival and so a group of explorers travel through a newly discovered wormhole to find a suitable planet to sustain human life.It amazes me how Christopher Nolan manages to come up with ideas like this. I admire how ambitious he is with his projects and Interstellar may be his most ambitious project to date. Despite its very long runtime, Interstellar never drags and that's because of the astounding visuals and emotion he put into this story. This is, without a doubt, one of his best looking films. There are just some films that are meant to be watched on a large screen with speakers to gain the full experience and Interstellar is one of those films. I honestly couldn't tell which scenes had visual effects and which had practical effects. They both blend so well and seamlessly to create some insane and phenomenal visuals that I think will age extremely well. The cinematography is amazing and you really get a sense that what you're watching is an epic. The sound is equally fantastic and Hans Zimmer's score as usual is incredible. It's a much more eerie score than what I'm used to hearing from Hans Zimmer but I liked it and though it fit well with the scale and stakes of the story.I've always been a fan of Matthew McConaughey I really loved his work here. His entire character has a very emotional arc and I felt the relationship he had with his daughter. A particular scene where we see McConaughey break down is easily one of Nolan's most emotional moments that is sure to leave people crying. For a child performance, I thought Mackenzie Foy and Jessica Chastain did a great job playing his daughter. Anne Hathaway was also really good as well as Michael Caine. There was an actor who I didn't expect to see but was pleasantly surprised when he turned up. I do wish there was more to Casey Affleck and Timothée Chalamet. They both play the son of McConaughey but there was barely any development done to that character for me to care about him.Whilst Interstellar is a visual spectacle and portrays a heartfelt and emotional relationship really well, it's certainly not a perfect film. The dialogue isn't anything special and at times very cheesy especially with one monologue delivered by Hathaway. I'm also not completely sold on the ending. For this story and how high the stakes were, I felt the film wrapped up way too nicely.Despite my issues with Interstellar, I still think it's a solid and emotional film with terrific performances from everyone, some interesting concepts that I'll be pondering over and breathtaking visuals that will stand the test of time.\"\n",
    "review = punc_clean(review)\n",
    "review = lemmatize_text(review)\n",
    "review = remove_stopword(review)\n",
    "review = tfidf_vectorizer.transform([review])\n",
    "lsvc_tfidf.predict(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3ebf01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later use.\n",
    "pickle.dump(lsvc_tfidf,open('sentiment_model.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674aa1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84333e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50e98d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
